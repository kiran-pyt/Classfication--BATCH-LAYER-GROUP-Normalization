# Comparative study of Batch,Layer,Group Normalization
Classification Project

o	Implemented an advanced MNIST digit prediction model utilizing my finest architecture. Replaced the default Batch Normalization with three distinct approaches: Group Normalization, Layer Normalization, and a fusion of L1 regularization with Batch Normalization
o	These adaptations showcase my expertise in optimizing neural network architectures for enhanced performance and flexibility.

